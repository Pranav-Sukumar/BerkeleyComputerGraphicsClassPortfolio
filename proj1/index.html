<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Project 1: Rasterizer</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="f0c71865-f615-46e3-a818-9593563fe69b" class="page sans"><header><img class="page-cover-image" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/Screen_Shot_2023-02-14_at_6.40.50_PM.png" style="object-position:center 50%"/><h1 class="page-title">Project 1: <strong>Rasterizer</strong></h1></header><div class="page-body"><h1 id="29b878aa-7b51-45e9-8f94-a8c077fac52c" class="">Ashwat Chidambaram, Pranav Sukumar - CS 284A (Spring 2023)</h1><h1 id="a6c31f7a-f8ae-445f-b186-ec899a2575d4" class="">Project Overview</h1><p id="fbddb334-68ac-4137-9a3b-db71fdcc0c4d" class="">In this project, we built a system to rasterize and render images onto a screen. Starting off with the most basic of tasks for rendering single-color triangles, we built the foundations for displaying simple images through techniques such as the 3-line test and using same-size sample buffers. Thereafter, we proceeded to implement a powerful technique called supersampling, which is a method to reduce artifacts such as jaggies and aliasing in our images. This drastically improved our overall image quality when higher supersampling rates were used, as the image visually appeared much smoother overall. We also added support for various core transformations (specifically rotation, translation, and scaling) in order to manipulate shapes and objects. We also implemented barycentric coordinates and used it to draw triangles with smooth color gradients interpolated across the entire span of the triangle based on its vertices. Finally building off the previous parts, we implemented pixel sampling and level sampling which allows for the application of texture mapping to our images. We improved the quality of our texture mapping through implementing different pixel sampling methods (nearest, linear) and mipmap level sampling methods (zero, nearest, linear). Ultimately at the end of it all, we have implemented the algorithms to use a combination of supersampling (4 options), pixel sampling (2 options), and level sampling (3 options) for a total of 24 different choices to produce the best visual quality of images on our computer screen. </p><p id="6a62b36c-233e-444f-a2ab-9f1f4488565c" class="">Through our time working on this project, we were able to take all the theoretical concepts we learned during lecture, and apply/implement them to a fully-functioning basic rasterization/visualization system. However, the process to code up this project was quite challenging as we were beginners to C++, which is quite different than languages like Python and Java. In addition, getting used to the codebase took some time as well, as we needed to get a solid high-level understanding of what all the parts of the codebase did, along with the intricacies within each file in order to know what to edit to accomplish our tasks. On the side, we also faced a few smaller issues such as handling edge cases for small parts of the images, the standard data type and numerical issues, etc. Overall though, it truly felt worth it and rewarding at the end as our final code works in totality, and we learned so many things along the way that will prove to be beneficial for the upcoming projects in this class!</p><h2 id="5470b349-a78a-4ce5-a972-669cd945e2b1" class="">Task 1: <strong><strong>Drawing Single-Color Triangles</strong></strong></h2><h3 id="d28dd417-5f2f-4954-9362-f2ac6eeda57e" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Algorithm and Approach</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="8c4e9317-7abf-4743-a368-c9d30b5becac" class="">For Task 1, we implemented a rasterization algorithm for triangles which began by finding the smallest/tightest bounding box that could fully contain the triangle. The bounding box was calculated by finding the minimum and maximum x and y values over all three vertices. Once this bounding box was defined, we iterated over each point within the box (with the offset of 0.5 in the x and y directions to ensure the center of each pixel was considered) and performed a 3-line test using a helper function called <code>inside_triangle()</code> to verify if the specific coordinate was within the triangle. If the point was determined to be inside the triangle, we proceeded to rasterize it by calling the <code>rasterize_point()</code> function, which was responsible for assigning the corresponding color to the respective pixel in the sample buffer.</p><h3 id="43908fd8-a944-407b-ab59-61f746dea2e4" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Efficiency</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="6824f072-0df7-4ce3-8a44-028062793c35" class="">In terms of its efficiency, our approach was equivalent to the one that checks each sample within the triangle&#x27;s bounding box, as that is exactly the method we followed as well. Therefore, the effectiveness of this approach is neither better nor worse than such an algorithm.</p><p id="6cb748b4-477a-43a9-8551-595e8ea2ca80" class="">
</p><figure id="74349f7d-8b65-47ce-b271-4200cb950c61" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-42-27.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-42-27.png"/></a><figcaption>svg/basic/test4.svg output - note the jaggies present in the image (made clearer by the zoomed-in pixel inspector)</figcaption></figure><h2 id="160443a1-dfa7-443a-b371-a69e9689bbdb" class=""><strong><strong>Task 2: Antialiasing by Supersampling</strong></strong></h2><h3 id="3ab3f008-cb5e-4289-bcd0-0223ebe92cfd" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong>Overview</strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="fd62ed85-9637-4e1f-8f22-21a9f125bae5" class="">For Task 2, we implemented our supersampling algorithm in order to improve the overall image quality, by reducing aliasing and mitigating “jaggies” from our previous work in Task 1. The basic premise of supersampling is that it samples individual pixels into smaller fragments (and thus at a higher rate) than the original full-size pixels, and thereafter aggregates data from higher sampling frequencies to produce a smoother blended overall image at the original resolution.</p><h3 id="e96fc2fa-765e-482d-99aa-66dde379babd" class="">Data Structures</h3><p id="97e23369-64c6-4bd3-afda-ffdf0cfeab4e" class="">The only data structure we needed to modify for this part was the <code>sample_buffer</code>. We increase the size by a factor of <code>sample_rate</code> in order to store the extra pixel information of our supersample. We do not modify the size of the frame buffer however, as that the final output should maintain the original size and resolution of our image as expected.</p><h3 id="52a1fb18-81b4-4aaa-ba01-50f1bb5902c8" class="">Methodology and Approach</h3><p id="c8ab36fb-bcf4-492f-a7a1-2327f4863dcb" class="">To accomplish our overall supersampling approach, we took the following steps and made the following modifications to the rasterization pipeline:</p><ol type="1" id="1bbc9a08-a145-4ee2-bee6-999161eb4180" class="numbered-list" start="1"><li>Given that the entire supersample is technically a factor of <code>sample_rate</code> larger than the original size, this means the width and height need to scale up by a factor of <code>sqrt(sample_rate)</code>. As a result, we scale all the triangle coordinates in our <code>rasterize_triangle()</code> function by this factor.</li></ol><ol type="1" id="0f2d99d9-1d74-4514-8d7f-bcabd0c2ed84" class="numbered-list" start="2"><li>Thereafter, we iterate over these new larger-scale of pixels in the supersample (which is thus significantly more points than before at the original unscaled resolution). We proceed through the same process as Task 1 by searching over the triangle’s bounding box, performing the scaled 3-line test to determine which points fall in the triangle, and assigning colors accordingly to the <code>sample_buffer</code> at our higher resolution.</li></ol><ol type="1" id="63b65f0c-6059-4f08-b2d5-e73f21363c4c" class="numbered-list" start="3"><li>We also made slight modifications in the <code>rasterize_point()</code> and <code>fill_pixel()</code> functions, as singular points at the original resolution may now correspond to multiple points in the higher resolution supersampled <code>sample_buffer</code>. Since we don’t need to anti-alias points or lines (<code>rasterize_point()</code> is called by <code>rasterize_line()</code>), we modified these functions to fill in all nearby pixels in an area of <code>sample_rate</code> so they subsample properly in the final end result for the frame buffer. This ensures that all the information obtained from the supersampled pixels is properly taken into account when the final picture is rendered.</li></ol><ol type="1" id="edcb1bf3-ff68-43ea-b8e4-9417d57282a2" class="numbered-list" start="4"><li>Given that the larger supersampling resolution does not match the original frame buffer resolution, we finally made modifications in the <code>resolve_to_framebuffer()</code> function to “downsample” our supersample back to the original output image resolution. To achieve this, we iterate over all pixels in a region area of <code>sample_rate</code> from the <code>sample_buffer</code>, and within this supersampled region we simply average out all the color values, and finally assign the original single pixel coordinate to that color in the framebuffer. This technique of averaging out the color values is a very effective way to reduce aliasing and produce a much smoother picture.</li></ol><h3 id="391888a7-e53c-4c17-a547-71d8f316dbf6" class="">Analysis</h3><p id="377a3172-dc21-4431-bfde-55b20d9253b0" class="">Based on the results, we can see that supersampling is useful because it significantly mitigates jaggies and aliasing for the colors, thus improving the overall appearance of the images to the viewer. The reason it works well is because it considers pixels at a finer granularity (higher sampling rate), so we can better assess not just simply whether a pixel is part of a triangle, but also how much of that pixel is contained in the triangle. Visually, this allows us to go beyond the simplistic binary color choice of an empty vs. colored pixel, and rather further assign a color intensity (brighter or darker hues) based on our supersampled understanding of the image. This allows for smoother transitions and gradients on the edges of our triangles, instead of sudden color changes like previously implemented which is very sharp and edgy. As you zoom out and look at the image as a whole, it appears much more seamless to the human eye.</p><p id="e24e6d0d-d1d4-419d-88a9-ac03318ec757" class="">
</p><p id="6abd6234-2ddc-44ca-813c-667507823fe7" class="">
</p><figure id="b951a249-1306-4023-8658-c88aae52b0b9" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-1.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-1.png"/></a><figcaption>svg/basic/test4.svg output with <strong>supersample rate of 1 </strong>sample per pixel - note the jaggies present in the image (made clearer by the zoomed-in pixel inspector)</figcaption></figure><figure id="6cc89050-beb5-4838-877c-5ee0a7aa75ac" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-7.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-7.png"/></a><figcaption>svg/basic/test4.svg output with <strong>supersample rate of 4</strong> samples per pixel - note the <em>slight</em> anti-aliasing resulting from the supersampling (made clearer by the zoomed-in pixel inspector)</figcaption></figure><figure id="730b5f57-335b-49b1-82ed-d9e9dfaa95bc" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-10.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-44-10.png"/></a><figcaption>svg/basic/test4.svg output with <strong>supersample rate of 16</strong> samples per pixel - note the <em>heavy</em> amount of anti-aliasing resulting from the supersampling (made clearer by the zoomed-in pixel inspector)</figcaption></figure><h2 id="2b141f02-c11d-4a44-8a6b-359c9e67669b" class=""><strong><strong>Task 3: Transforms</strong></strong></h2><p id="e864eb51-6de1-491f-bec6-198b178372e5" class="">For Task 3, we implemented various pixel transformations, in particular for supporting translation, scaling, and rotations. To showcase our successful efforts, we decided to change up the picture.</p><p id="a0db843a-c80d-4195-a34b-b058bba22782" class="">Don’t get me wrong, cubeman is a cool dude, but you know what’s cooler than cubeman? That’s right, Iron Man. We upgraded cubeman to include his very own hand-crafted arc reactor in his chest, taught him how to fly in the latest Mark LXXXVI suit by angling his hands downward with flames shooting out of his hands and legs, and finally gave him the signature red and gold helmet and suit colors to complete the fit. There is undoubtedly no better, more powerful, intelligent, charismatic, philanthropic, and rizzed-out cubeman in the entire history of CS 284A than our very own Iron Man edition. Avengers assemble!</p><figure id="e5e2c44a-fda0-4d81-aa6d-2867e1d54284" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-44-4.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-44-4.png"/></a><figcaption>the new and improved cubeman, also known as the one and only… Iron Man!</figcaption></figure><h2 id="f79e9a74-8bdb-4e66-841f-0e84f588899d" class=""><strong><strong>Task 4: Barycentric Coordinates</strong></strong></h2><p id="64fa08d5-a4bb-417a-9e5f-23d100727b4b" class="">Barycentric coordinates are a method of representing points within triangles, utilizing weights assigned to the three vertices in order to interpolate values inside the triangle. The three weights (alpha, beta, and gamma) are calculated using proportional distances to the vertices and the line equation. These three weights are multiplied by corresponding values at the vertices (these can be colors, positions, or texture coordinates), added up, and ultimately result in an accurate point location within the triangle. This technology can be utilized to create attractive color mixes and gradients within various polygons. </p><p id="8dc1ede5-69fb-40ce-9972-1d5a7932c619" class="">For example, the figure below displays an isosceles triangle that we have generated, with weighted points between the red, green, and blue colors that were assigned to each point in the triangle. As we traverse the figure, the colors at any single point will steadily shift in accordance with the r/g/b vertices that are closest to it. This produces a gradient effect, as the colors blend together in a gentle, progressive transition. Moreover, by adjusting the weight of each vertex, we can precisely control the color combination at any point, allowing us to create even more graphical effects.</p><figure id="a4d03c1c-7169-47cb-aec0-98d2124424ac" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-59-7.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-59-7.png"/></a><figcaption>a screenshot of our custom-rendered barycentric interpolated triangle</figcaption></figure><p id="32c6ad7c-10ce-4762-acb2-cc1de32e46c1" class="">
</p><figure id="d0c1b94b-22fb-494a-ac0b-09923993ad87" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-1-46.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_15-1-46.png"/></a><figcaption>a screenshot of our svg/basic/test7.svg color wheel output</figcaption></figure><h3 id="3137b75b-f810-407c-9d7e-2c971b4c8141" class=""><strong>Barycentric Coordinates Algorithm and Approach:</strong></h3><ol type="1" id="39c23c2b-29f9-4d15-897d-0c3e0fc68f0e" class="numbered-list" start="1"><li>In <code>rasterize_interpolated_color_triangle()</code> after checking if a sample was inside the triangle, we calculated alpha, beta, and gamma values using the formulas from the lecture slides:</li></ol><pre id="04da8fc9-8f46-403e-822e-ced5df65d8e0" class="code"><code>float alpha = ((-(x-x1)*(y2-y1))+((y-y1)*(x2-x1))) / ((-(x0-x1)*(y2-y1))+((y0-y1)*(x2-x1)));
float beta = ((-(x-x2)*(y0-y2))+((y-y2)*(x0-x2))) / ((-(x1-x2)*(y0-y2))+((y1-y2)*(x0-x2))); 
float gamma = 1-alpha-beta;</code></pre><ol type="1" id="c3f8ce86-0992-463e-82ef-3b28251c5044" class="numbered-list" start="2"><li>Once we calculated the alpha, beta, and gamma values, we calculated the appropriate color by multiplying each weight with the corresponding vertex value:</li></ol><pre id="fa80be0b-deef-4a32-85de-68c15066f1b2" class="code"><code>Color final_color = (alpha * c0) + (beta * c1) + (gamma * c2)</code></pre><h2 id="6ff7071d-ca12-460a-a43a-66b2308cd2b0" class=""><strong><strong>Task 5: &quot;Pixel sampling&quot; for Texture Mapping</strong></strong></h2><h3 id="288d642e-1693-4570-8661-79fd54f5844e" class=""><strong>Pixel Sampling Overview:</strong></h3><p id="b4f27be7-89cb-4465-a4dc-0eb21933fc65" class="">Pixel sampling is a technique that samples points on a texture image in order to render a pixel on a rasterized screen-space triangle. Texture mapping samples a texture map in order to rasterize a triangle on the screen.</p><p id="833ac269-b6d7-4201-9871-dbeb129b4d9d" class="">The two main pixel sampling methods are <em>nearest</em> sampling and <em>bilinear </em>sampling:</p><ul id="6a8d92c6-19ed-48e3-80c2-ab1f1da41f2c" class="bulleted-list"><li style="list-style-type:disc"><strong>Nearest Neighbor Sampling</strong>: This is a simple method of determining the color of a pixel by simply sampling the nearest pixel coordinate by rounding the x/y coordinates, and then assigning that color to the original target pixel on the image. This method is simple and quick to compute but unfortunately does not produce the best visual output as it simply adopts a color from one of its neighbors, instead of accounting for them all. If no supersampling is used, nearest neighbor sampling can lead to aliasing and jaggies.</li></ul><ul id="11d5b212-9f78-483d-8b27-3357201c3fc5" class="bulleted-list"><li style="list-style-type:disc"><strong>Bilinear Pixel Interpolation Sampling:</strong> This is a slightly more complex method of determining the color of a pixel by considering all four nearest neighbor pixels, and uses <em><em><em><em><em><em><em><em>linear interpolation</em></em></em></em></em></em></em></em> (”lerp”) to provide weights to these four neighbors’ colors and ultimately determine the final color for the original target pixel on the image. This method is more involved and clever as it takes into account all four neighbors and computes a color that blends surrounding colors together.</li></ul><h3 id="81139254-74fc-4b10-a92e-705546859c4a" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Pixel Sampling Algorithm and Approach:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><ol type="1" id="19eb9814-d9ce-42f2-86ae-c1286c0d8363" class="numbered-list" start="1"><li>We first had to implement the <code>rasterize_textured_triangle()</code> function in rasterizer.cpp. This function takes in the standard x0, y0, x1, y1, x2, y2 locations for the 3 vertices of the screen-space triangle. It also takes in the texture-map-space locations u0, v0, u1, v1, u2, v2 for the 3 vertices of the texture map space triangle. Given any point in the screen-space triangle, the pixel sampling algorithm needs to interpolate the correct location in the texture-map-space and fetch the appropriate color to render. To fetch the appropriate location p_uv, barycentric coordinates were used (see below for the exact logic). This was passed into a new <code>SampleParams</code> struct used in a function call to <code>Texture.sample()</code>which returns the color to render.<pre id="2fd4e6d4-6747-426b-bf40-d1d506f56411" class="code"><code>result.x = (u0 * alpha) + (u1 * beta) + (u2 * gamma);
result.y = (v0 * alpha) + (v1 * beta) + (v2 * gamma);
params.p_uv = result;</code></pre></li></ol><ol type="1" id="100adc12-8b2b-43b1-b8c3-d933907b1543" class="numbered-list" start="2"><li>We also had to implement the <code>Texture.sample()</code> function. For Task 5, all this function had to do was call either <code>Texture.sample_nearest()</code>or <code>Texture.sample_bilinear()</code> depending on the parameters passed in.</li></ol><ol type="1" id="ad969fe9-1cb6-419f-8974-349477205111" class="numbered-list" start="3"><li>We had to implement <code>Texture.sample_nearest()</code> for nearest neighbor sampling. In this function, we calculated the u and v values by indexing into the barycentric vector uv and scaling it by (width-1) or (height-1), and rounding it to the nearest integer (as opposed to flooring since we want the <em>nearest</em> neighbor, not the <em>lowest</em> neighbor). We subtract 1 from the width and height since a pixel is defined as the center of a cell, and this accounts for off by one errors. Because the barycentric coordinates could be slightly smaller than 0 or slightly greater than 1, we ran into segfault errors for accessing out of bounds memory. To fix this, we had to explicitly clamp the values of u and v to be between 0 and either the height or width. Finally, now that we had accurate u and v values, we called <code>mip.get_texel(u,v)</code> to return the appropriate color.</li></ol><ol type="1" id="5a426a85-b3a2-4254-992e-6fa069da544b" class="numbered-list" start="4"><li>We had to implement <code>Texture.sample_bilinear()</code> for bilinear pixel interpolation sampling. For bilinear pixel interpolation sampling, we calculated the u00, u01, u10, and u11 values for the 4 adjacent pixels by taking all combinations of the floor and ceiling for the u and v coordinates of the sample point. We calculated the s and t values by subtracting the original u and v values by u00. After ensuring the values were clamped (as they were for nearest neighbors), we interpolated the colors at the corresponding texels using a lerp helper function we wrote. The lerp logic is the same as the algorithm presented in lecture and the code can be seen below:</li></ol><pre id="0cf26bbc-d730-4123-b4a5-c921c419b4f9" class="code"><code>Color u0 = lerp_custom(s, u00, u10);
Color u1 = lerp_custom(s, u01, u11);
Color result = lerp_custom(t, u0, u1);</code></pre><p id="12647a5a-828e-426d-b1f5-bc7b0ce6a8e2" class="">
</p><h3 id="14c87f1c-6eb4-41aa-854b-b00d937b64a1" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Pixel Sampling Results:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><div id="9dd6afa0-f038-42c0-a927-deed8d89889b" class="column-list"><div id="417851c2-fe62-40f1-9832-d92835e667e2" style="width:50%" class="column"><figure id="ca828e21-22b3-4692-9ed3-2adeadd9e3db" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-1-50.png"><img style="width:432px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-1-50.png"/></a><figcaption>svg/texmap/test5.svg output: <strong>nearest sampling</strong> + <strong>supersample rate of 1</strong> samples per pixel</figcaption></figure></div><div id="579e591b-5b37-42bd-a81c-dbc7c1435f61" style="width:50%" class="column"><figure id="469baeba-6a7b-403f-8973-d104e3d958da" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-1-54.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-1-54.png"/></a><figcaption>svg/texmap/test5.svg output: <strong>bilinear</strong> <strong>sampling</strong> + <strong>supersample rate of 1</strong> samples per pixel</figcaption></figure></div></div><div id="314eca80-8704-44d7-82b2-c243dacadd51" class="column-list"><div id="ef27a0db-7f50-4abc-8334-82072dbfa559" style="width:50%" class="column"><figure id="67228705-f87a-4c8b-884d-0bb0bbf1ce48" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-2-1.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-2-1.png"/></a><figcaption>svg/texmap/test5.svg output: <strong>nearest sampling</strong> + <strong>supersample rate of 16</strong> samples per pixel</figcaption></figure></div><div id="eb47c7ae-edd5-4d7c-ad6d-be73c12c2af1" style="width:50%" class="column"><figure id="e5953c45-fe95-4169-b479-78d38f6397eb" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-2-4.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_16-2-4.png"/></a><figcaption>svg/texmap/test5.svg output: <strong>bilinear</strong> <strong>sampling</strong> + <strong>supersample rate of 16</strong> samples per pixel</figcaption></figure></div></div><h3 id="72d5274f-5abc-45ef-a936-2870e93c067f" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Relative Differences and Analysis:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="1948ca28-9a38-448a-8836-fc756233f1a4" class="">There are various differences when comparing the results above. First and foremost, it is very clear that bilinear pixel interpolation has a clear advantage over nearest neighbor sampling, as the images look much more smooth and blended. This stark difference is especially apparent at a low supersampling rate (such as 1), which can easily be observed looking at the zoomed-in pixel inspector previews on the top-right of each image. However, the difference between nearest sampling vs. bilinear sampling becomes much less apparent as the sampling rate increases (up to 16). This is because the supersampling approach works to antialias images at the final screen space level, whereas pixel sampling is essentially antialising at the texture space level beforehand. Thus, when we have a high supersample rate on the screen space, the prior texture space pixel sampling is not very apparent as supersampling antialises the output anyway. However, when we basically prevent supersampling entirely at 1 sample per pixel, the antialised changes that pixel sampling produces on the texture space is much more apparent and displayed to the viewer.</p><h2 id="e3c43c89-3f19-4e28-b129-eab0a5e961ee" class="">T<strong><strong>ask 6: &quot;Level Sampling&quot; with Mipmaps for Texture Mapping</strong></strong></h2><h3 id="87bf78b8-cc56-45ec-a8fb-8e1f5dd0ac2e" class=""><strong>Level Sampling Overview: </strong></h3><p id="5d450ee2-5471-4d45-98c8-9766161bb019" class="">Level sampling is when you sample from precomputed different resolutions of the texture. Level sampling helps render images that have different depths of view. It allows the foreground to be rendered with a high resolution, and saves computation power and time by rendering parts of the background with a lower resolution.</p><p id="fd577302-f06b-442b-93df-7e7fb6a949ca" class="">The three level sampling methods implemented in this project were Level 0 Sampling, Nearest Sampling, and Linear Sampling</p><ul id="4efaca09-34ec-48e4-bc52-3ab6ecd3cf6f" class="bulleted-list"><li style="list-style-type:disc"><strong>Level 0 Sampling:</strong> In level 0 sampling, the entire texture is sampled at level 0 in the texture space and lower resolutions are not used.</li></ul><ul id="8dce15ea-e46f-42da-b328-2e5d96d364b3" class="bulleted-list"><li style="list-style-type:disc"><strong>Nearest Sampling:</strong> In nearest sampling, the floating point level is computed using the formula presented in lecture, and the mipmap level that is closest in value to the computed level is used.</li></ul><ul id="3b76f4c1-3b18-47a2-8c93-f970682b5a6d" class="bulleted-list"><li style="list-style-type:disc"><strong>Linear Sampling: </strong>In linear sampling, the floating point level is computed. The final output is a weighted sum using one sample from each of the adjacent mipmap levels.</li></ul><h3 id="5d13ee23-b9f8-4e99-b520-1faaca6cbe9e" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Level Sampling Algorithm and Approach:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><ol type="1" id="05a5a8c4-e882-46b9-97fc-cd6a5f537225" class="numbered-list" start="1"><li>We first had to modify the <code>rasterize_textured_triangle()</code> function in rasterizer.cpp. For level sampling we have to calculate the <code>p_dx_uv</code>and <code>p_dy_uv</code> vectors. We computed these by using barycentric coordinates similar to how <code>p_uv</code> was previously calculated. However for <code>p_dx_uv</code>, we used (x+1, y) to interpolate and for <code>p_dy_uv</code> we used (x, y+1) to interpolate. </li></ol><ol type="1" id="4cc049f2-16e5-46e4-ad22-0d7f49512a59" class="numbered-list" start="2"><li>We then had to implement the <code>Texture.get_level() </code>function in texture.cpp. We first calculated difference vectors by subtracting <code>p_uv</code> from <code>p_dx_uv</code>and <code>p_dy_uv</code>. We then scaled the difference vectors by the width and height respectively. We then used the formula from class to return the floating point level (see below for the code):</li></ol><pre id="21c8884d-bd69-408e-b061-426f11a2398a" class="code code-wrap"><code>float l = max(sqrt((difference_vector_x.x * difference_vector_x.x) + (difference_vector_x.y * difference_vector_x.y)), sqrt((difference_vector_y.x * difference_vector_y.x)+ (difference_vector_y.y * difference_vector_y.y)));     
float d = log2(l);</code></pre><ol type="1" id="46e1b980-c6b7-4bfd-8f06-2eac3940d15b" class="numbered-list" start="3"><li>For Linear Layer Sampling, we had to compute the weighted sum of colors using one sample from each of the adjacent mipmap levels. The weight for the lower sample was the floating point value of the level minus the floor of the level and the weight for the upper sample was the ceiling of the level minus the floating point value of the level.</li></ol><h3 id="305488f9-071c-429e-8319-412b4fe3a706" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Performance Tradeoffs:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="e6441b2e-5ec7-4e37-9d07-25d81561f97d" class="">Analyzing the tradeoffs between speed, memory usage, and antialiasing power between pixel sampling, level sampling, and supersampling, there are a plethora of factors to consider. From a speed perspective, pixel sampling is quicker since it needs to run the least computation, but doesn’t always provide the best visual outputs free from artifacts<strong><strong><strong>. </strong></strong></strong>From a memory perspective, level sampling will take an extra 1/3 amount of memory for storing the mipmap with multiple resolution texture maps compared to a single one (which is also slower to compute), but is beneficial as it provides better antialiasing and visual outputs compared to pixel sampling. From an antialiasing power perspective, supersampling produces by far the best outputs compared to both approaches with scaling capabilities, but unfortunately lacks in the sense of high computation required, especially as the scale increases (which also means a larger <em>sample buffer </em>size so higher memory consumption).</p><h3 id="91c7ad04-2706-4985-b3b6-c5cceb37e156" class="">Level Sampling<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong> Results:</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h3><p id="bef30ca0-c6ee-4ca4-bbe6-cc92443dd685" class="">
</p><div id="5915e6ef-170a-4132-953f-a2b593075cb1" class="column-list"><div id="6a4d75d7-43f7-447a-ae77-a972e3b32548" style="width:50%" class="column"><figure id="2457798c-2e19-4fe5-8aa1-4d4c30c48f92" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-37.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-37.png"/></a><figcaption><strong>Level 0 Level</strong> Sampling &amp; <strong>Nearest</strong> <strong>Pixel</strong> Sampling</figcaption></figure></div><div id="b39dea17-cf5f-41fc-a592-eecd3ae2c863" style="width:50%" class="column"><figure id="a34ba682-634d-4f9c-b01e-a7ae95aabc4f" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-41.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-41.png"/></a><figcaption><strong>Level 0</strong> Level Sampling &amp; <strong>Bilinear</strong> <strong>Pixel</strong> Sampling</figcaption></figure></div></div><div id="da89e6e0-a042-4604-95b1-e90583e4db4e" class="column-list"><div id="c568c551-b06b-4a0d-beb1-6042f824212e" style="width:50%" class="column"><figure id="a4f52d64-5c75-4036-8116-b45961f148a7" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-47.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-47.png"/></a><figcaption><strong>Nearest Level</strong> Sampling &amp; <strong>Nearest</strong> Pixel Sampling</figcaption></figure><p id="15b8d080-1b70-44e3-82d2-a91ca5179bfb" class="">
</p><h3 id="82c0c494-320c-4324-ac3e-09922d24d492" class="">Original Image (From Above):</h3></div><div id="b88be226-1993-4dff-80f2-d3804ddf9f91" style="width:50%" class="column"><figure id="09176f74-cc6d-4b3b-818c-65780c4f9a46" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-51.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_18-17-51.png"/></a><figcaption><strong>Nearest Level</strong> Sampling &amp; <strong>Bilinear</strong> <strong>Pixel</strong> Sampling</figcaption></figure><p id="3a208b3d-bdba-494d-97ab-28a29a841bca" class="">
</p><p id="da719046-4405-4e99-ad15-143f6b1e44bb" class="">
</p></div></div><figure id="2b017e98-74bf-46cd-8d16-512a57687250" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/iron_man.png"><img style="width:1200px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/iron_man.png"/></a></figure><h2 id="a91c89e0-a905-4231-b662-9f0888a73acb" class="">Extra Credit<strong><strong>: Competition Image</strong></strong></h2><figure id="b8df7a58-f603-48b4-9083-57df33ac361e" class="image"><a href="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-44-4.png"><img style="width:1600px" src="Project%201%20Rasterizer%20f0c71865f61546e3a8189593563fe69b/screenshot_2-14_14-44-4.png"/></a><figcaption>Witness the amazing creation that we are proud to call our competition image: the glorious “Iron (cube)Man”.</figcaption></figure><p id="f4f6d3e8-2d43-4ec6-8150-54dfdbc0301e" class="">To create Iron Man, we rotated the arms to face downwards so that the respulsors in his arm allow him to take off. We added triangles to show the powerful fire of Iron Man’s repulsors on both his arms and legs. Iron Man’s suit would not operate without power from his arc reactor, so we drew an arc reactor on his chest using triangles. We changed the color of Iron Man to match his signature hot-rod red, and painted his helmet gold with another triangle along with two eyes. We made the entire svg from scratch without using any scripts.</p><h1 id="4d294639-503e-402e-85cb-82ed500c7d67" class="">Conclusion</h1><p id="a62bab07-812b-46b6-8778-b46ecbdd0d9b" class="">Overall, this was a really intriguing and fun project to work on! We truly learned a lot about coding in C++ and various algorithms used for optimal graphics rendering. We had fun working with an Iron Man theme for this project. It was satisfying to see the awesome results of visualizing smooth anti-aliased images without jaggies from our code!</p><h1 id="f87c4c53-998c-4c5e-82d5-e9415817f14e" class="">Link to Website</h1><p id="2608fb7d-0668-4cdf-b21a-739ae8f6189a" class=""><a href="https://pranav-sukumar.github.io/BerkeleyComputerGraphicsClassPortfolio/proj1/index.html">https://pranav-sukumar.github.io/BerkeleyComputerGraphicsClassPortfolio/proj1/index.html</a> </p></div></article></body></html>